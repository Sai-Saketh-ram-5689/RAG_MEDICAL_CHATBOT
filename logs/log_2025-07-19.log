2025-07-19 11:50:19,384 - INFO - MAking the vectorstore....
2025-07-19 11:50:19,385 - INFO - Loading files from data/
2025-07-19 11:51:07,278 - INFO - Sucesfully fetched 759 documents
2025-07-19 11:51:07,278 - INFO - Splitting 759 documents into chunks
2025-07-19 11:51:07,721 - INFO - Generated 7080 text chunks
2025-07-19 11:51:07,722 - INFO - Generating your new vectorstore
2025-07-19 11:51:07,722 - INFO - Intializing our Huggingface embedding model
2025-07-19 11:52:30,430 - INFO - Use pytorch device_name: cpu
2025-07-19 11:52:30,430 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 11:52:40,999 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 11:54:52,616 - INFO - Loading faiss with AVX2 support.
2025-07-19 11:54:59,786 - INFO - Successfully loaded faiss with AVX2 support.
2025-07-19 11:54:59,817 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-07-19 11:55:00,541 - INFO - Saving vectorstoree
2025-07-19 11:55:00,669 - INFO - Vectostore saved sucesfulyy...
2025-07-19 11:55:00,678 - INFO - Vectorstore created sucesfully....
2025-07-19 12:30:38,362 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.22.133.234:5000
2025-07-19 12:30:38,363 - INFO - [33mPress CTRL+C to quit[0m
2025-07-19 12:31:16,682 - ERROR - Exception on / [GET]
Traceback (most recent call last):
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "S:\rag_med\app\application.py", line 48, in index
    return render_template("index.html" , messages=session.get("messages" , []))
  File "S:\rag_med\venv\Lib\site-packages\flask\templating.py", line 149, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
  File "S:\rag_med\venv\Lib\site-packages\jinja2\environment.py", line 1087, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
           ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "S:\rag_med\venv\Lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
                                 ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\flask\templating.py", line 65, in get_source
    return self._get_source_fast(environment, template)
           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\flask\templating.py", line 99, in _get_source_fast
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: index.html
2025-07-19 12:31:16,693 - INFO - 127.0.0.1 - - [19/Jul/2025 12:31:16] "[35m[1mGET / HTTP/1.1[0m" 500 -
2025-07-19 12:31:18,253 - INFO - 127.0.0.1 - - [19/Jul/2025 12:31:18] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-07-19 12:31:20,154 - ERROR - Exception on / [GET]
Traceback (most recent call last):
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 1511, in wsgi_app
    response = self.full_dispatch_request()
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 919, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 917, in full_dispatch_request
    rv = self.dispatch_request()
  File "S:\rag_med\venv\Lib\site-packages\flask\app.py", line 902, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)  # type: ignore[no-any-return]
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^
  File "S:\rag_med\app\application.py", line 48, in index
    return render_template("index.html" , messages=session.get("messages" , []))
  File "S:\rag_med\venv\Lib\site-packages\flask\templating.py", line 149, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
  File "S:\rag_med\venv\Lib\site-packages\jinja2\environment.py", line 1087, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
           ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\jinja2\environment.py", line 1016, in get_template
    return self._load_template(name, globals)
           ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\jinja2\environment.py", line 975, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
  File "S:\rag_med\venv\Lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
                                 ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\flask\templating.py", line 65, in get_source
    return self._get_source_fast(environment, template)
           ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "S:\rag_med\venv\Lib\site-packages\flask\templating.py", line 99, in _get_source_fast
    raise TemplateNotFound(template)
jinja2.exceptions.TemplateNotFound: index.html
2025-07-19 12:31:20,160 - INFO - 127.0.0.1 - - [19/Jul/2025 12:31:20] "[35m[1mGET / HTTP/1.1[0m" 500 -
2025-07-19 12:34:15,283 - INFO - 127.0.0.1 - - [19/Jul/2025 12:34:15] "GET / HTTP/1.1" 200 -
2025-07-19 12:34:23,868 - INFO - Loading vector store for context
2025-07-19 12:34:23,869 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:35:35,665 - INFO - Use pytorch device_name: cpu
2025-07-19 12:35:35,665 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:35:45,872 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:35:45,874 - INFO - Loading existing vectorstore...
2025-07-19 12:35:45,887 - INFO - Loading faiss with AVX2 support.
2025-07-19 12:35:49,758 - INFO - Successfully loaded faiss with AVX2 support.
2025-07-19 12:35:49,782 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.
2025-07-19 12:35:49,965 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:35:52,817 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:35:52,819 - INFO - Successfully created the QA chain
2025-07-19 12:35:56,275 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:35:56,329 - INFO - 127.0.0.1 - - [19/Jul/2025 12:35:56] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:35:56,347 - INFO - 127.0.0.1 - - [19/Jul/2025 12:35:56] "GET / HTTP/1.1" 200 -
2025-07-19 12:36:39,546 - INFO - Loading vector store for context
2025-07-19 12:36:39,546 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:36:39,556 - INFO - Use pytorch device_name: cpu
2025-07-19 12:36:39,556 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:36:43,218 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:36:43,218 - INFO - Loading existing vectorstore...
2025-07-19 12:36:43,488 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:36:45,750 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:36:45,751 - INFO - Successfully created the QA chain
2025-07-19 12:36:46,125 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:36:46,143 - INFO - 127.0.0.1 - - [19/Jul/2025 12:36:46] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:36:46,157 - INFO - 127.0.0.1 - - [19/Jul/2025 12:36:46] "GET / HTTP/1.1" 200 -
2025-07-19 12:36:55,803 - INFO - Loading vector store for context
2025-07-19 12:36:55,804 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:36:55,809 - INFO - Use pytorch device_name: cpu
2025-07-19 12:36:55,809 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:37:00,582 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:37:00,582 - INFO - Loading existing vectorstore...
2025-07-19 12:37:00,719 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:37:02,648 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:37:02,649 - INFO - Successfully created the QA chain
2025-07-19 12:37:03,397 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:37:03,412 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:03] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:37:03,428 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:03] "GET / HTTP/1.1" 200 -
2025-07-19 12:37:16,426 - INFO - Loading vector store for context
2025-07-19 12:37:16,427 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:37:16,432 - INFO - Use pytorch device_name: cpu
2025-07-19 12:37:16,432 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:37:19,900 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:37:19,901 - INFO - Loading existing vectorstore...
2025-07-19 12:37:19,980 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:37:21,072 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:37:21,073 - INFO - Successfully created the QA chain
2025-07-19 12:37:21,414 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:37:21,424 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:21] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:37:21,439 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:21] "GET / HTTP/1.1" 200 -
2025-07-19 12:37:34,293 - INFO - Loading vector store for context
2025-07-19 12:37:34,293 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:37:34,297 - INFO - Use pytorch device_name: cpu
2025-07-19 12:37:34,297 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:37:37,719 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:37:37,720 - INFO - Loading existing vectorstore...
2025-07-19 12:37:37,795 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:37:38,915 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:37:38,916 - INFO - Successfully created the QA chain
2025-07-19 12:37:39,247 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:37:39,256 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:39] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:37:39,273 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:39] "GET / HTTP/1.1" 200 -
2025-07-19 12:37:50,605 - INFO - Loading vector store for context
2025-07-19 12:37:50,606 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:37:50,610 - INFO - Use pytorch device_name: cpu
2025-07-19 12:37:50,611 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:37:55,684 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:37:55,685 - INFO - Loading existing vectorstore...
2025-07-19 12:37:55,766 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:37:56,867 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:37:56,868 - INFO - Successfully created the QA chain
2025-07-19 12:37:57,193 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:37:57,203 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:57] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:37:57,219 - INFO - 127.0.0.1 - - [19/Jul/2025 12:37:57] "GET / HTTP/1.1" 200 -
2025-07-19 12:40:04,646 - INFO - 127.0.0.1 - - [19/Jul/2025 12:40:04] "GET / HTTP/1.1" 200 -
2025-07-19 12:40:09,371 - INFO - 127.0.0.1 - - [19/Jul/2025 12:40:09] "GET / HTTP/1.1" 200 -
2025-07-19 12:40:10,334 - INFO - 127.0.0.1 - - [19/Jul/2025 12:40:10] "GET / HTTP/1.1" 200 -
2025-07-19 12:40:10,547 - INFO - 127.0.0.1 - - [19/Jul/2025 12:40:10] "GET / HTTP/1.1" 200 -
2025-07-19 12:41:13,136 - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.22.133.234:5000
2025-07-19 12:41:13,136 - INFO - [33mPress CTRL+C to quit[0m
2025-07-19 12:41:18,540 - INFO - 127.0.0.1 - - [19/Jul/2025 12:41:18] "GET / HTTP/1.1" 200 -
2025-07-19 12:41:33,379 - INFO - 10.22.133.234 - - [19/Jul/2025 12:41:33] "GET / HTTP/1.1" 200 -
2025-07-19 12:41:35,065 - INFO - 10.22.133.234 - - [19/Jul/2025 12:41:35] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-07-19 12:41:49,558 - INFO - Loading vector store for context
2025-07-19 12:41:49,558 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:41:49,564 - INFO - Use pytorch device_name: cpu
2025-07-19 12:41:49,565 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:41:52,967 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:41:52,968 - INFO - Loading existing vectorstore...
2025-07-19 12:41:53,063 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:41:54,510 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:41:54,512 - INFO - Successfully created the QA chain
2025-07-19 12:41:54,839 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:41:54,852 - INFO - 10.22.133.234 - - [19/Jul/2025 12:41:54] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:41:54,866 - INFO - 10.22.133.234 - - [19/Jul/2025 12:41:54] "GET / HTTP/1.1" 200 -
2025-07-19 12:42:36,146 - INFO - Loading vector store for context
2025-07-19 12:42:36,147 - INFO - Intializing our Huggingface embedding model
2025-07-19 12:42:36,151 - INFO - Use pytorch device_name: cpu
2025-07-19 12:42:36,151 - INFO - Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2
2025-07-19 12:42:39,628 - INFO - Huggingface embedding model loaded sucesfully....
2025-07-19 12:42:39,628 - INFO - Loading existing vectorstore...
2025-07-19 12:42:39,722 - INFO - Loading LLM from Groq using LLaMA3 model...
2025-07-19 12:42:41,738 - INFO - LLM loaded successfully from Groq.
2025-07-19 12:42:41,739 - INFO - Successfully created the QA chain
2025-07-19 12:42:42,962 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions "HTTP/1.1 200 OK"
2025-07-19 12:42:42,980 - INFO - 10.22.133.234 - - [19/Jul/2025 12:42:42] "[32mPOST / HTTP/1.1[0m" 302 -
2025-07-19 12:42:42,996 - INFO - 10.22.133.234 - - [19/Jul/2025 12:42:42] "GET / HTTP/1.1" 200 -
